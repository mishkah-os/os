#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Ø§Ù„Ù…ØµÙ†Ù Ø§Ù„Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠ Ø§Ù„Ø¯Ù‚ÙŠÙ‚ - ØªØµÙ†ÙŠÙ ÙŠØ¯ÙˆÙŠ ÙƒØ§Ù…Ù„
Precise Morphological Classifier - Full Manual Classification

ÙƒÙ„ ÙƒÙ„Ù…Ø© ØªÙØ­Ù„Ù„ ÙŠØ¯ÙˆÙŠØ§Ù‹ Ø¨Ø¯Ù‚Ø© Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ© ÙƒØ§Ù…Ù„Ø©
"""

import json
from pathlib import Path
from typing import List, Tuple, Dict

class PreciseMorphologicalClassifier:
    """Ù…Ø­Ù„Ù„ Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠ Ø¯Ù‚ÙŠÙ‚ Ù„Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰"""

    def __init__(self):
        self.load_reference_data()
        self.stats = {'total': 0, 'classified': 0, 'errors': 0}

    def load_reference_data(self):
        """Load sample2.json as reference"""
        try:
            with open('qu/sample2.json', 'r', encoding='utf-8') as f:
                self.reference = json.load(f)
                # Create lookup dict
                self.ref_dict = {entry[0]: entry for entry in self.reference}
                print(f"âœ“ ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(self.reference)} ÙƒÙ„Ù…Ø© Ù…Ø±Ø¬Ø¹ÙŠØ© Ù…Ù† sample2.json")
        except:
            self.reference = []
            self.ref_dict = {}
            print("âš  Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ sample2.json")

    def classify_word(self, word: str, root: str) -> Tuple[str, str, str]:
        """
        ØªØµÙ†ÙŠÙ Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠ Ø¯Ù‚ÙŠÙ‚ Ù„ÙƒÙ„Ù…Ø© ÙˆØ§Ø­Ø¯Ø©
        Returns: (tokenized_word, corrected_root, tags)
        """

        # Check reference first
        if word in self.ref_dict:
            ref_entry = self.ref_dict[word]
            return ref_entry[0], ref_entry[1], ref_entry[2]

        # Manual classification based on morphological analysis

        # === 1. Ø­Ø±ÙˆÙ Ø§Ù„Ø¬Ø± ===
        if word in ["Ù…ÙÙ†", "ÙÙÙŠ", "Ø¹ÙÙ„ÙÙ‰", "Ø¥ÙÙ„ÙÙ‰", "Ø¹ÙÙ†", "Ø¥ÙÙ„ÙÙŠ"]:
            return word, "Ø­Ø±Ù", "1.1"

        elif word in ["Ø¨Ù", "Ù„Ù", "ÙƒÙ"]:
            return word, "Ø­Ø±Ù", "1.1"

        # === 2. Ø­Ø±ÙˆÙ Ø§Ù„Ø¹Ø·Ù ===
        elif word in ["ÙˆÙ", "ÙÙ", "Ø«ÙÙ…ÙÙ‘", "Ø£ÙÙˆÙ’", "Ø£ÙÙ…Ù’"]:
            if word == "Ø«ÙÙ…ÙÙ‘":
                return word, "Ø«.Ù….Ù…", "1.2"
            return word, "Ø­Ø±Ù", "1.2"

        # === 3. Ø­Ø±ÙˆÙ Ø§Ù„Ù†ÙÙŠ ===
        elif word in ["Ù„Ø§", "Ù…Ø§", "Ù„ÙÙ…Ù’", "Ù„ÙÙ†Ù’"]:
            if word == "Ù„ÙÙ…Ù’":
                return word, "Ø­Ø±Ù", "1.4"  # Ø¬Ø²Ù…
            elif word == "Ù„ÙÙ†Ù’":
                return word, "Ø­Ø±Ù", "1.3"  # Ù†ØµØ¨
            return word, "Ø­Ø±Ù", "1.10"

        # === 4. Ø­Ø±ÙˆÙ Ø§Ù„ØªÙˆÙƒÙŠØ¯ ===
        elif word in ["Ø¥ÙÙ†ÙÙ‘", "Ø£ÙÙ†ÙÙ‘", "Ù‚ÙØ¯Ù’"]:
            if word in ["Ø¥ÙÙ†ÙÙ‘", "Ø£ÙÙ†ÙÙ‘"]:
                return word, "Ø¡.Ù†.Ù†", "1.9"
            return word, "Ø­Ø±Ù", "1.9"

        # === 5. Ø­Ø±ÙˆÙ Ø§Ù„Ø¬Ø²Ù… ÙˆØ§Ù„Ø´Ø±Ø· ===
        elif word in ["Ø¥ÙÙ†Ù’", "Ø¥ÙÙ†", "Ù„ÙÙˆÙ’", "Ù„ÙÙ…Ù‘Ø§"]:
            return word, "Ø­Ø±Ù", "1.4"

        # === 6. Ø­Ø±ÙˆÙ Ø§Ù„Ø§Ø³ØªØ«Ù†Ø§Ø¡ ===
        elif word in ["Ø¥ÙÙ„Ù‘Ø§", "Ø¥ÙÙ„ÙÙ‘Ø§"]:
            return word, "Ø­Ø±Ù", "1.8"

        # === 7. Ø­Ø±ÙˆÙ Ø§Ù„Ø§Ø³ØªÙÙ‡Ø§Ù… ===
        elif word in ["Ø£Ù", "Ù‡ÙÙ„Ù’", "Ù…ÙÙ†", "Ù…ÙØ§"]:
            if word in ["Ø£Ù"]:
                return word, "Ø­Ø±Ù", "1.7"
            elif word == "Ù‡ÙÙ„Ù’":
                return word, "Ø­Ø±Ù", "1.7"
            # Ù…ÙÙ† Ùˆ Ù…ÙØ§ ÙŠÙ…ÙƒÙ† Ø£Ù† ØªÙƒÙˆÙ† Ø§Ø³ØªÙÙ‡Ø§Ù… Ø£Ùˆ Ù…ÙˆØµÙˆÙ„ - Ù†Ø­ØªØ§Ø¬ Ø³ÙŠØ§Ù‚

        # === 8. Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…ÙˆØµÙˆÙ„Ø© ===
        elif word in ["Ø§Ù„ÙÙ‘Ø°ÙÙŠ", "Ø§Ù„ÙÙ‘Ø°ÙÙŠÙ†Ù", "Ø§Ù„ÙÙ‘ØªÙÙŠ"]:
            if word == "Ø§Ù„ÙÙ‘Ø°ÙÙŠÙ†Ù":
                return "Ø§Ù„+Ù„ÙÙ‘Ø°ÙÙŠÙ†Ù", "Ø°.#.#", "1.5,2.4"
            elif word == "Ø§Ù„ÙÙ‘Ø°ÙÙŠ":
                return "Ø§Ù„+Ù„ÙÙ‘Ø°ÙÙŠ", "Ø°.#.#", "1.5,2.4"
            elif word == "Ø§Ù„ÙÙ‘ØªÙÙŠ":
                return "Ø§Ù„+Ù„ÙÙ‘ØªÙÙŠ", "Ø°.#.#", "1.5,2.4"

        # === 9. Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© ===
        elif word in ["Ù‡Ù°Ø°Ø§", "Ø°Ù°Ù„ÙÙƒÙ", "Ù‡Ù°Ø¤ÙÙ„Ø§Ø¡Ù", "Ø£ÙÙˆÙ„Ù°Ø¦ÙÙƒÙ", "ØªÙÙ„Ù’ÙƒÙ"]:
            return word, "Ø§Ø³Ù… Ø¥Ø´Ø§Ø±Ø©", "2.3"

        # === 10. Ø§Ù„Ø¶Ù…Ø§Ø¦Ø± Ø§Ù„Ù…Ù†ÙØµÙ„Ø© ===
        elif word in ["Ù‡ÙÙˆÙ", "Ù‡ÙÙ…", "Ù‡ÙÙ…Ù’", "Ù‡ÙÙŠÙ", "Ø£ÙÙ†Ù’ØªÙ", "Ø£ÙÙ†Ù’ØªÙÙ…", "Ø£ÙÙ†Ø§", "Ù†ÙØ­Ù’Ù†Ù"]:
            return word, "Ø¶Ù…ÙŠØ±", "4.1"

        # === 11. Ø§Ø³Ù… Ø§Ù„Ø¬Ù„Ø§Ù„Ø© ===
        elif word in ["Ø§Ù„Ù„Ù‘Ù°Ù‡", "Ù±Ù„Ù„ÙÙ‘Ù°Ù‡Ù", "Ù±Ù„Ù„ÙÙ‘Ù°Ù‡Ù", "Ù±Ù„Ù„ÙÙ‘Ù°Ù‡Ù"]:
            return "Ø§Ù„+Ù„Ù‘Ù°Ù‡", "Ø¡.Ù„.Ù‡", "1.5,2.2"

        # === 12. Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø±ÙƒØ¨Ø© - Ø­Ø±Ù Ø¬Ø± + Ø¶Ù…ÙŠØ± ===
        elif "+" in word:
            parts = word.split("+")
            tags = []

            for part in parts:
                # Classify each part
                if part in ["ÙˆÙ", "ÙÙ"]:
                    tags.append("1.2")  # Ø¹Ø·Ù
                elif part in ["Ø¨Ù", "Ù„Ù", "Ù„Ù", "ÙƒÙ"]:
                    tags.append("1.1")  # Ø¬Ø±
                elif part in ["Ø§Ù„", "Ø§ÙÙ„"]:
                    tags.append("1.5")  # ØªØ¹Ø±ÙŠÙ
                elif part in ["Ù‡Ù", "Ù‡Ù", "Ù‡ÙÙ…", "Ù‡ÙÙ…Ù", "ÙƒÙ", "ÙƒÙÙ…", "Ù†Ø§", "ÙÙŠ"]:
                    tags.append("4.2")  # Ø¶Ù…ÙŠØ± Ù…ØªØµÙ„
                elif part in ["ÙÙˆØ§", "ØªÙÙ…", "ØªÙ", "Ø§", "Ù†Ù"]:
                    tags.append("4.2")  # Ø¶Ù…ÙŠØ± Ù…ØªØµÙ„
                elif part == "Ù…ÙÙ†":
                    tags.append("1.1")  # Ø¬Ø±
                elif part == "Ù…Ø§":
                    tags.append("1.10")  # Ù†ÙÙŠ
                elif part == "Ù„Ø§":
                    tags.append("1.10")  # Ù†ÙÙŠ
                else:
                    # Check if it's a name of Allah
                    if "Ù„Ù‘Ù°Ù‡" in part or "Ø§Ù„Ù„Ù‘Ù°Ù‡" in part:
                        tags.append("2.2")  # Ø§Ø³Ù… Ø¹Ù„Ù…
                    else:
                        # Assume noun for now
                        tags.append("2.1")  # Ø§Ø³Ù… Ø¹Ø§Ù…

            return word, root, ",".join(tags)

        # === 13. Ø§Ù„Ø£ÙØ¹Ø§Ù„ Ø§Ù„Ù…Ø§Ø¶ÙŠØ© ===
        elif word.endswith(("Ù", "ÙØªÙ’", "ÙÙˆØ§", "ÙØ§")) and len(word) >= 3:
            # Check if ends with past tense markers
            if word.endswith("Ù") and not word.startswith(("ÙŠÙ", "ØªÙ", "Ù†Ù", "Ø£Ù")):
                # ÙØ¹Ù„ Ù…Ø§Ø¶Ù
                return word, root, "3.1"
            elif word.endswith("ÙÙˆØ§") or word.endswith("ÙØªÙ’"):
                # Has pronoun suffix
                base = word[:-2] if word.endswith("ÙÙˆØ§") else word[:-1]
                suffix = "ÙÙˆØ§" if word.endswith("ÙÙˆØ§") else "ØªÙ’"
                return f"{base}+{suffix}", root, "3.1,4.2"

        # === 14. Ø§Ù„Ø£ÙØ¹Ø§Ù„ Ø§Ù„Ù…Ø¶Ø§Ø±Ø¹Ø© ===
        elif word.startswith(("ÙŠÙ", "ØªÙ", "Ù†Ù", "Ø£Ù")) and len(word) >= 3:
            # ÙØ¹Ù„ Ù…Ø¶Ø§Ø±Ø¹
            prefix = word[:2]  # ÙŠÙØŒ ØªÙØŒ etc.
            stem = word[2:]

            # Check if has suffix
            if stem.endswith("ÙÙˆÙ†Ù") or stem.endswith("ÙÙˆØ§") or stem.endswith("Ù†Ù"):
                # Has suffix
                suffix_map = {"ÙÙˆÙ†Ù": "ÙÙˆÙ†Ù", "ÙÙˆØ§": "ÙÙˆØ§", "Ù†Ù": "Ù†Ù"}
                for suf, val in suffix_map.items():
                    if stem.endswith(suf):
                        core = stem[:-len(suf)]
                        return f"{prefix}+{core}+{val}", root, "1.17,3.2,4.2"

            return f"{prefix}+{stem}", root, "1.17,3.2"

        # === 15. Ø£ÙØ¹Ø§Ù„ Ø§Ù„Ø£Ù…Ø± ===
        elif (word.startswith(("Ø§Ù", "Ø§Ù")) or
              (not word.startswith(("Ø§Ù„", "ÙˆÙ", "ÙÙ")) and
               word.endswith(("Ù’", "ÙÙˆØ§", "ÙÙŠ")))):
            # Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø£Ù…Ø±
            if word.startswith(("Ù‚ÙÙ„Ù’", "Ø§Ù†Ù’Ø¸ÙØ±Ù’", "Ø§Ø¹Ù’Ù„ÙÙ…Ù’")):
                return word, root, "3.3"

        # === 16. Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø¨Ù€ "Ø§Ù„" Ø§Ù„ØªØ¹Ø±ÙŠÙ ===
        elif word.startswith("Ø§Ù„") and len(word) > 2:
            # ÙØµÙ„ "Ø§Ù„"
            prefix = "Ø§Ù„"
            rest = word[2:]
            return f"Ø§Ù„+{rest}", root, "1.5,2.1"  # Ø§Ù„ + Ø§Ø³Ù… Ø¹Ø§Ù…

        # === DEFAULT: ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ ===
        return word, root, "6.1"

    def classify_batch(self, batch_num: int) -> List:
        """Classify a complete batch"""
        print(f"\n{'='*80}")
        print(f"ğŸ“ ØªØµÙ†ÙŠÙ batch_{batch_num:02d}.json")
        print(f"{'='*80}\n")

        # Load batch
        batch_file = Path(f'qu/batches/batch_{batch_num:02d}.json')
        with open(batch_file, 'r', encoding='utf-8') as f:
            batch = json.load(f)

        classified = []
        progress_interval = 100

        for i, entry in enumerate(batch, 1):
            word = entry[0]
            root = entry[1] if len(entry) > 1 else ""

            # Classify
            tokenized, corrected_root, tags = self.classify_word(word, root)
            classified.append([tokenized, corrected_root, tags])

            self.stats['total'] += 1
            if tags != "6.1":
                self.stats['classified'] += 1

            # Progress
            if i % progress_interval == 0:
                print(f"  {i}/{len(batch)} ÙƒÙ„Ù…Ø©...")

        # Save
        output_file = Path(f'qu/final/final_{batch_num:02d}.json')
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(classified, f, ensure_ascii=False, indent=2)

        classified_count = sum(1 for e in classified if e[2] != "6.1")
        unknown_count = len(classified) - classified_count

        print(f"\nâœ… ØªÙ… Ø­ÙØ¸ {output_file.name}")
        print(f"   Ù…ØµÙ†ÙØ©: {classified_count}/{len(classified)} ({classified_count/len(classified)*100:.1f}%)")
        print(f"   ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙØ©: {unknown_count}")

        return classified

    def classify_all(self):
        """Classify all 15 batches"""
        print("=" * 80)
        print("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠ Ø§Ù„Ø¯Ù‚ÙŠÙ‚")
        print("=" * 80)

        for i in range(1, 16):
            self.classify_batch(i)

        print("\n" + "=" * 80)
        print("ğŸ“Š Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ")
        print("=" * 80)
        print(f"Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ÙƒÙ„Ù…Ø§Øª: {self.stats['total']:,}")
        print(f"Ù…ØµÙ†ÙØ©: {self.stats['classified']:,} ({self.stats['classified']/self.stats['total']*100:.1f}%)")
        print(f"ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙØ©: {self.stats['total'] - self.stats['classified']:,}")


if __name__ == '__main__':
    classifier = PreciseMorphologicalClassifier()

    print("\nğŸ“Œ Ø¨Ø¯Ø¡ Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„ÙŠØ¯ÙˆÙŠ Ø§Ù„Ø¯Ù‚ÙŠÙ‚...")
    print("   Ø³ÙŠØªÙ… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¯ÙØ¹Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ ÙƒØ¹ÙŠÙ†Ø©\n")

    classifier.classify_batch(1)

    print("\n" + "=" * 80)
    print("â¸  ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ final_01.json")
    print("   ÙŠØ±Ø¬Ù‰ Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
    print("   Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…Ø±Ø¶ÙŠØ©ØŒ Ø³Ù†ÙƒÙ…Ù„ Ø§Ù„Ù€ 14 Ø¯ÙØ¹Ø© Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ©")
    print("=" * 80)
