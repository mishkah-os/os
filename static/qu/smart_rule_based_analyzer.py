#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import json
import re
from typing import Tuple, List, Dict

class SmartRuleBasedAnalyzer:
    """Ù…Ø­Ù„Ù„ Ø°ÙƒÙŠ ÙŠØ¯ÙˆÙŠ ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø³ Ø§Ù„Ù„ØºÙˆÙŠØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"""

    def __init__(self):
        # Ù‚Ø§Ù…ÙˆØ³ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø¹Ø±ÙˆÙØ© Ø¨Ø§Ù„ÙƒØ§Ù…Ù„
        self.known_words = {
            # Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø¨Ø³ÙŠØ·Ø©
            'Ù…ÙÙ†': ['Ù…ÙÙ†', 'Ù….Ù†', '1.1'],
            'ÙÙÙŠ': ['ÙÙÙŠ', 'Ù.#', '1.1'],
            'Ø¹ÙÙ„ÙÙ‰': ['Ø¹ÙÙ„ÙÙ‰', 'Ø¹.Ù„.Ùˆ', '1.1'],
            'Ø¥ÙÙ„ÙÙ‰': ['Ø¥ÙÙ„ÙÙ‰', 'Ø¡.Ù„.ÙŠ', '1.1'],
            'Ø¹ÙÙ†Ù’': ['Ø¹ÙÙ†Ù’', 'Ø­Ø±Ù', '1.1'],
            'Ø­ÙØªÙÙ‘Ù‰': ['Ø­ÙØªÙÙ‘Ù‰', 'Ø­Ø±Ù', '1.1'],
            'Ù…ÙØ¹Ù': ['Ù…ÙØ¹Ù', 'Ø­Ø±Ù', '1.1'],
            'Ù„Ø§': ['Ù„Ø§', 'Ù„.#', '1.10'],
            'Ù…ÙØ§': ['Ù…ÙØ§', 'Ù….#', '1.10'],
            'Ø¥ÙÙ†': ['Ø¥ÙÙ†', '#.Ù†', '1.4'],
            'Ø¥ÙÙ†ÙÙ‘': ['Ø¥ÙÙ†ÙÙ‘', '#.Ù†.Ù†', '1.9'],
            'Ø£ÙÙ†ÙÙ‘': ['Ø£ÙÙ†ÙÙ‘', '#.Ù†.Ù†', '1.9'],
            'Ù‚ÙØ¯Ù’': ['Ù‚ÙØ¯Ù’', 'Ø­Ø±Ù', '1.9'],
            'Ù„ÙÙ…Ù’': ['Ù„ÙÙ…Ù’', 'Ø­Ø±Ù', '1.4'],
            'Ù„ÙÙ†Ù’': ['Ù„ÙÙ†Ù’', 'Ø­Ø±Ù', '1.3'],
            'Ù‡ÙÙ„Ù’': ['Ù‡ÙÙ„Ù’', 'Ø­Ø±Ù', '1.7'],
            'ÙƒÙÙŠÙ’ÙÙ': ['ÙƒÙÙŠÙ’ÙÙ', 'Ùƒ.ÙŠ.Ù', '1.7'],
            'Ø¥ÙÙ„Ù‘Ø§': ['Ø¥ÙÙ„Ù‘Ø§', '#.Ù„.Ù„', '1.8'],
            'Ø¨ÙÙ„Ù’': ['Ø¨ÙÙ„Ù’', 'Ø­Ø±Ù', '1.14'],
            'Ù„Ù°ÙƒÙÙ†Ù’': ['Ù„Ù°ÙƒÙÙ†Ù’', 'Ø­Ø±Ù', '1.18'],
            'Ø£ÙÙˆÙ’': ['Ø£ÙÙˆÙ’', 'Ø­Ø±Ù', '1.2'],
            'Ø£ÙÙ…Ù’': ['Ø£ÙÙ…Ù’', 'Ø­Ø±Ù', '1.2'],
            'Ù„ÙÙˆÙ’': ['Ù„ÙÙˆÙ’', 'Ø­Ø±Ù', '1.4'],
            'Ø§Ù„Ù„Ù‘Ù°Ù‡': ['Ø§Ù„Ù„Ù‘Ù°Ù‡', 'Ø¡.Ù„.Ù‡', '2.2'],
            'Ù…ÙÙˆØ³ÙÙ‰': ['Ù…ÙÙˆØ³ÙÙ‰', 'NTWS', '2.2'],
            'Ø¥ÙØ¨Ù’Ø±Ø§Ù‡ÙÙŠÙ…': ['Ø¥ÙØ¨Ù’Ø±Ø§Ù‡ÙÙŠÙ…', 'NTWS', '2.2'],
            'Ø¬ÙÙ‡ÙÙ†ÙÙ‘Ù…': ['Ø¬ÙÙ‡ÙÙ†ÙÙ‘Ù…', 'NTWS', '2.2'],
            'ÙÙØ±Ù’Ø¹ÙÙˆÙ’Ù†': ['ÙÙØ±Ù’Ø¹ÙÙˆÙ’Ù†', 'NTWS', '2.2'],
            'Ù‡Ù°Ø°Ø§': ['Ù‡Ù°Ø°Ø§', 'Ø§Ø³Ù… Ø¥Ø´Ø§Ø±Ø©', '2.3'],
            'Ø°Ù°Ù„ÙÙƒÙ': ['Ø°Ù°Ù„ÙÙƒÙ', 'Ø§Ø³Ù… Ø¥Ø´Ø§Ø±Ø©', '2.3'],
            'Ø£ÙÙˆÙ„Ù°Ø¦ÙÙƒÙ': ['Ø£ÙÙˆÙ„Ù°Ø¦ÙÙƒÙ', 'Ø§Ø³Ù… Ø¥Ø´Ø§Ø±Ø©', '2.3'],
            'ØªÙÙ„Ù’ÙƒÙ': ['ØªÙÙ„Ù’ÙƒÙ', 'Ø§Ø³Ù… Ø¥Ø´Ø§Ø±Ø©', '2.3'],
            'Ù‡Ù°Ø¤ÙÙ„Ø§Ø¡Ù': ['Ù‡Ù°Ø¤ÙÙ„Ø§Ø¡Ù', 'Ø§Ø³Ù… Ø¥Ø´Ø§Ø±Ø©', '2.3'],
            'Ø§Ù„ÙÙ‘Ø°ÙÙŠ': ['Ø§Ù„ÙÙ‘Ø°ÙÙŠ', 'Ø¡.Ù„.Ø°', '2.4'],
            'Ø§Ù„ÙÙ‘Ø°ÙÙŠÙ†Ù': ['Ø§Ù„ÙÙ‘Ø°ÙÙŠÙ†Ù', 'Ø¡.Ù„.Ø°', '2.4'],
            'Ø§Ù„ÙÙ‘ØªÙÙŠ': ['Ø§Ù„ÙÙ‘ØªÙÙŠ', 'Ø¡.Ù„.Ø°', '2.4'],
            'Ù‡ÙÙˆÙ': ['Ù‡ÙÙˆÙ', 'Ø¶Ù…ÙŠØ±', '4.1'],
            'Ù‡ÙÙ…': ['Ù‡ÙÙ…', 'Ø¶Ù…ÙŠØ±', '4.1'],
            'Ù‡ÙÙŠÙ': ['Ù‡ÙÙŠÙ', 'Ø¶Ù…ÙŠØ±', '4.1'],
            'Ø£ÙÙ†Ù’ØªÙÙ…': ['Ø£ÙÙ†Ù’ØªÙÙ…', 'Ø¶Ù…ÙŠØ±', '4.1'],
            'Ø£ÙÙ†Ù’ØªÙ': ['Ø£ÙÙ†Ù’ØªÙ', 'Ø¶Ù…ÙŠØ±', '4.1'],
            'Ø£ÙÙ†Ø§': ['Ø£ÙÙ†Ø§', 'Ø¶Ù…ÙŠØ±', '4.1'],
            'Ù†ÙØ­Ù’Ù†Ù': ['Ù†ÙØ­Ù’Ù†Ù', 'Ø¶Ù…ÙŠØ±', '4.1'],
            'Ø¥ÙØ°Ø§': ['Ø¥ÙØ°Ø§', 'Ø¸Ø±Ù', '5.1'],
            'Ø¥ÙØ°Ù’': ['Ø¥ÙØ°Ù’', 'Ø¸Ø±Ù', '5.1'],
            'Ø¨ÙØ¹Ù’Ø¯': ['Ø¨ÙØ¹Ù’Ø¯', 'Ø¨.Ø¹.Ø¯', '5.1'],
            'Ù‚ÙØ¨ÙÙ„': ['Ù‚ÙØ¨ÙÙ„', 'Ù‚.Ø¨.Ù„', '5.1'],
            'ÙŠÙÙˆÙ’Ù…ÙØ¦ÙØ°Ù': ['ÙŠÙÙˆÙ’Ù…ÙØ¦ÙØ°Ù', 'ÙŠ.Ùˆ.Ù…', '5.1'],
            'Ø«ÙÙ…ÙÙ‘': ['Ø«ÙÙ…ÙÙ‘', 'Ø«.Ù….Ù…', '5.2'],
            'Ø¹ÙÙ†Ù’Ø¯': ['Ø¹ÙÙ†Ù’Ø¯', 'Ø¹.Ù†.Ø¯', '5.2'],
            'Ø¯ÙÙˆÙ†': ['Ø¯ÙÙˆÙ†', 'Ø¯.Ùˆ.Ù†', '5.2'],
            'Ø¨ÙÙŠÙ’Ù†Ù': ['Ø¨ÙÙŠÙ’Ù†Ù', 'Ø¨.ÙŠ.Ù†', '5.2'],
            'Øµ': ['Øµ', 'NTWS', '6.1'],
        }

        # Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ ÙˆØ§Ù„ØµÙØ§Øª Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©
        self.common_nouns_adjectives = {
            'Ø¹ÙØ°Ø§Ø¨': '2.5',
            'Ø®ÙÙŠÙ’Ø±': '2.1',
            'Ø®ÙÙ„Ù’Ù‚': '2.5',
            'Ø¹ÙÙ„ÙÙŠÙ…': '7.0',
            'Ø±ÙØ­ÙÙŠÙ…': '7.0',
            'Ù…ÙØ¨ÙÙŠÙ†': '7.0',
            'ÙƒÙØªØ§Ø¨': '2.1',
            'Ø³ÙÙ…Ø§Ø¡': '2.1',
            'Ø£ÙØ±Ù’Ø¶': '2.1',
            'Ù†ÙØ§Ø±': '2.1',
            'Ø¬ÙÙ†ÙÙ‘Ø©': '2.1',
            'Ø­ÙÙ‚Ù‘': '2.5',
            'Ø¹ÙØ²ÙÙŠØ²': '7.0',
            'Ø¹ÙØ§Ù„ÙÙ…': '7.0',
            'Ù‚ÙÙˆÙ…': '2.1',
            'ÙŠÙÙˆÙ…': '2.1',
            'Ø´ÙÙŠÙ’Ø¡': '2.1',
            'Ù‚ÙÙˆÙ„': '2.5',
        }

    def analyze_word(self, word: str, root: str) -> List[str]:
        """ØªØ­Ù„ÙŠÙ„ ÙƒÙ„Ù…Ø© ÙˆØ§Ø­Ø¯Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø³"""

        # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„ÙƒÙ„Ù…Ø© Ù…Ø¹Ø±ÙˆÙØ© Ø¨Ø§Ù„ÙƒØ§Ù…Ù„
        if word in self.known_words:
            return self.known_words[word]

        # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„ÙƒÙ„Ù…Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ +
        if '+' in word:
            morphemes = word.split('+')
            tags_list = []

            for morpheme in morphemes:
                if morpheme in self.known_words:
                    tags_list.append(self.known_words[morpheme][2])
                else:
                    # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØµÙ†ÙŠÙ Ø§Ù„Ù…ÙˆØ±ÙÙŠÙ…
                    tag = self._classify_morpheme(morpheme)
                    tags_list.append(tag)

            tags = ','.join(tags_list)
            return [word, root, tags]

        # ØªØµÙ†ÙŠÙ Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ø¨Ø³ÙŠØ·Ø©
        tag = self._classify_single_word(word, root)
        return [word, root, tag]

    def _classify_morpheme(self, morpheme: str) -> str:
        """ØªØµÙ†ÙŠÙ Ø§Ù„Ù…ÙˆØ±ÙÙŠÙ… Ø§Ù„ÙˆØ§Ø­Ø¯"""

        # Ø­Ø±ÙˆÙ Ø§Ù„Ø¬Ø±
        if morpheme in ['Ù…ÙÙ†', 'ÙÙÙŠ', 'Ø¹ÙÙ„ÙÙ‰', 'Ø¥ÙÙ„ÙÙ‰', 'Ø¹ÙÙ†Ù’', 'Ø¨Ù', 'Ù„Ù', 'ÙƒÙ']:
            return '1.1'

        # Ø­Ø±ÙˆÙ Ø§Ù„Ø¹Ø·Ù
        if morpheme in ['ÙˆÙ', 'ÙÙ', 'Ø£ÙÙˆÙ’', 'Ø£ÙÙ…Ù’']:
            return '1.2'

        # Ø­Ø±ÙˆÙ Ø£Ø®Ø±Ù‰
        if morpheme in ['Ù„Ø§', 'Ù…ÙØ§']:
            return '1.10'
        if morpheme == 'Ø¥ÙÙ†':
            return '1.4'
        if morpheme == 'Ø¥ÙÙ†ÙÙ‘' or morpheme == 'Ø£ÙÙ†ÙÙ‘':
            return '1.9'

        # Ø¶Ù…Ø§Ø¦Ø± Ù…ØªØµÙ„Ø©
        if morpheme in ['Ù‡Ù', 'Ù‡ÙÙ…', 'ÙƒÙ', 'ÙƒÙÙ…', 'ÙÙˆØ§', 'ØªÙÙ…', 'Ù†Ø§', 'ÙÙŠ', 'Ù‡Ø§', 'ØªÙ', 'ÙÙˆÙ†Ù', 'ÙÙŠÙ’Ù†', 'Ù†ÙÙ‘']:
            return '4.2'

        # Ø¹Ù„Ù… + Ø¶Ù…ÙŠØ±
        if morpheme in ['Ù‡ÙÙ…', 'Ù‡Ù', 'Ù‡Ø§']:
            return '4.2'

        # Ø£Ø³Ù…Ø§Ø¡
        if morpheme in self.common_nouns_adjectives:
            return self.common_nouns_adjectives[morpheme]

        return '6.1'

    def _classify_single_word(self, word: str, root: str) -> str:
        """ØªØµÙ†ÙŠÙ ÙƒÙ„Ù…Ø© Ø¨Ø³ÙŠØ·Ø©"""

        # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø¬Ø°Ø± Ù…Ø¹Ø±ÙˆÙØ§Ù‹ ÙÙŠ Ø§Ù„Ù‚Ø§Ù…ÙˆØ³
        if word in self.common_nouns_adjectives:
            return self.common_nouns_adjectives[word]

        # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ÙØ¦Ø© Ù…Ù† Ø§Ù„Ø¬Ø°Ø±
        if root and root != 'X':
            # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø¬Ø°Ø± Ù…Ø¹Ø±ÙˆÙØ§Ù‹
            if len(root) >= 3:
                # Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø§Ø³Ù…Ø§Ù‹ Ø£Ùˆ ØµÙØ©
                return '2.1'

        return '6.1'


def process_all_batches_smart(batch_num: int):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© batch Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø°ÙƒÙŠØ©"""

    input_file = f'batches/batch_{batch_num:02d}.json'
    output_file = f'final/final_{batch_num:02d}.json'

    with open(input_file, 'r', encoding='utf-8') as f:
        data = json.load(f)

    analyzer = SmartRuleBasedAnalyzer()
    corrected_data = []

    for entry in data:
        word = entry[0]
        root = entry[1]

        # ØªØ­Ù„ÙŠÙ„ Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø°ÙƒÙŠØ©
        analyzed = analyzer.analyze_word(word, root)
        corrected_data.append(analyzed)

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(corrected_data, f, ensure_ascii=False, indent=2)

    return len(corrected_data)


# Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª
print("ğŸ”¬ Ø¬Ø§Ø±ÙŠ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ø°ÙƒÙŠØ© Ù„Ù„Ù…Ù„ÙØ§Øª...")
total_processed = 0

for i in range(1, 16):
    count = process_all_batches_smart(i)
    total_processed += count
    print(f"âœ“ Ù…Ø¹Ø§Ù„Ø¬Ø© batch_{i:02d}.json ({count} ÙƒÙ„Ù…Ø©)")

print(f"\nâœ“ Ø§ÙƒØªÙ…Ù„Øª Ù…Ø¹Ø§Ù„Ø¬Ø© {total_processed} ÙƒÙ„Ù…Ø©")
print("âœ“ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ØµØ­Ø­Ø© Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ù…Ø¬Ù„Ø¯ final/")
