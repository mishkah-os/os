#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ Ø§Ù„Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠ Ø§Ù„Ø¯Ù‚ÙŠÙ‚
Precise Morphological Reviewer

ÙŠØ±Ø§Ø¬Ø¹ ÙƒÙ„ ÙƒÙ„Ù…Ø© ÙÙŠ final_XX.json ÙˆÙŠØµØ­Ø­Ù‡Ø§ Ø­Ø³Ø¨:
- map.md (Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„ØªØµÙ†ÙŠÙ)
- sample2.json (Ø£Ù…Ø«Ù„Ø© Ù…Ø±Ø¬Ø¹ÙŠØ©)
- Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
"""

import json
from pathlib import Path
from typing import List, Tuple

class MorphologicalReviewer:
    def __init__(self):
        self.corrections = []
        self.stats = {
            'total': 0,
            'correct': 0,
            'corrected': 0,
            'unknown': 0
        }

    def analyze_word(self, word: str, root: str) -> Tuple[str, str, str]:
        """
        ØªØ­Ù„ÙŠÙ„ Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠ Ø¯Ù‚ÙŠÙ‚ Ù„ÙƒÙ„Ù…Ø© ÙˆØ§Ø­Ø¯Ø©
        Returns: (tokenized_word, root, tags)
        """

        # ØªØµØ­ÙŠØ­ Ø§Ù„ØªÙˆÙƒÙ†Ø² ÙˆØ§Ù„ØªØµÙ†ÙŠÙ Ø­Ø³Ø¨ Ø§Ù„ÙƒÙ„Ù…Ø©

        # === Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© ===
        if word == "Ù…Ø§":
            # ÙŠØ­ØªÙ…Ù„: Ù†ÙÙŠØŒ Ù…ÙˆØµÙˆÙ„ØŒ Ø§Ø³ØªÙÙ‡Ø§Ù… - Ù†Ø®ØªØ§Ø± Ø§Ù„Ø£ÙƒØ«Ø± Ø´ÙŠÙˆØ¹Ø§Ù‹
            return "Ù…Ø§", "Ù….#", "1.10"  # Ø­Ø±Ù Ù†ÙÙŠ (Ø§Ù„Ø£ÙƒØ«Ø± Ø´ÙŠÙˆØ¹Ø§Ù‹)

        elif word == "Ø§Ù„ÙÙ‘Ø°ÙÙŠÙ†Ù":
            return "Ø§Ù„+Ù„ÙÙ‘Ø°ÙÙŠÙ†Ù", "Ø°.#.#", "1.5,2.4"  # Ø§Ù„ + Ø§Ø³Ù… Ù…ÙˆØµÙˆÙ„

        elif word == "Ø£ÙÙ†ÙÙ‘":
            return "Ø£ÙÙ†ÙÙ‘", "Ø¡.Ù†.Ù†", "1.9"  # Ø­Ø±Ù ØªÙˆÙƒÙŠØ¯

        elif word == "Ø«ÙÙ…ÙÙ‘":
            return "Ø«ÙÙ…ÙÙ‘", "Ø«.Ù….Ù…", "1.2"  # Ø­Ø±Ù Ø¹Ø·Ù

        elif word == "Ø§Ù„ÙÙ‘Ø°ÙÙŠ":
            return "Ø§Ù„+Ù„ÙÙ‘Ø°ÙÙŠ", "Ø°.#.#", "1.5,2.4"  # Ø§Ù„ + Ø§Ø³Ù… Ù…ÙˆØµÙˆÙ„

        elif word == "Ø§Ù„Ù„Ù‘Ù°Ù‡":
            return "Ø§Ù„+Ù„Ù‘Ù°Ù‡", "Ø¡.Ù„.Ù‡", "1.5,2.2"  # Ø§Ù„ + Ø§Ø³Ù… Ø¹Ù„Ù…

        elif word.startswith("Ø§Ù„+") or word.startswith("ÙˆÙ+Ø§Ù„"):
            # Already tokenized - keep it
            return word, root, "6.1"  # Will be reviewed manually

        # === Ø§Ù„Ø£ÙØ¹Ø§Ù„ ===
        elif word.endswith("Ù") and len(word) >= 3:
            # ÙØ¹Ù„ Ù…Ø§Ø¶Ù likely
            return word, root, "3.1"

        elif word.startswith("ÙŠÙ") or word.startswith("ØªÙ") or word.startswith("Ù†Ù") or word.startswith("Ø£Ù"):
            # ÙØ¹Ù„ Ù…Ø¶Ø§Ø±Ø¹ likely
            prefix = word[0] + word[1]  # ÙŠÙØŒ ØªÙØŒ etc.
            stem = word[2:]
            if len(stem) >= 2:
                return f"{prefix}+{stem}", root, "1.17,3.2"

        # Default: return unchanged with 6.1
        return word, root, "6.1"

    def review_file(self, batch_num: int):
        """Review a single final file"""
        print(f"\n{'='*80}")
        print(f"ğŸ“ Ù…Ø±Ø§Ø¬Ø¹Ø© final_{batch_num:02d}.json")
        print(f"{'='*80}")

        # Load batch and final
        batch_file = Path(f'qu/batches/batch_{batch_num:02d}.json')
        final_file = Path(f'qu/final/final_{batch_num:02d}.json')

        with open(batch_file, 'r', encoding='utf-8') as f:
            batch = json.load(f)

        with open(final_file, 'r', encoding='utf-8') as f:
            final = json.load(f)

        # Review each word
        corrected_final = []
        corrections_made = 0

        for i, (batch_entry, final_entry) in enumerate(zip(batch, final)):
            batch_word = batch_entry[0]
            batch_root = batch_entry[1] if len(batch_entry) > 1 else ""

            final_word = final_entry[0]
            final_root = final_entry[1]
            final_tags = final_entry[2] if len(final_entry) > 2 else "6.1"

            self.stats['total'] += 1

            # Check if needs correction
            if final_tags == "6.1" or not final_tags:
                # Needs correction
                corrected_word, corrected_root, corrected_tags = self.analyze_word(batch_word, batch_root)

                if corrected_tags != "6.1":
                    corrections_made += 1
                    self.stats['corrected'] += 1
                    corrected_final.append([corrected_word, corrected_root, corrected_tags])
                else:
                    self.stats['unknown'] += 1
                    corrected_final.append([final_word, final_root, final_tags])
            else:
                # Already correct
                self.stats['correct'] += 1
                corrected_final.append(final_entry)

        # Save corrected file
        output_file = Path(f'qu/final/final_{batch_num:02d}_reviewed.json')
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(corrected_final, f, ensure_ascii=False, indent=2)

        print(f"âœ… ØªÙ… Ù…Ø±Ø§Ø¬Ø¹Ø© {len(final)} ÙƒÙ„Ù…Ø©")
        print(f"   ØªØµØ­ÙŠØ­Ø§Øª: {corrections_made}")
        print(f"   Ø­ÙØ¸ ÙÙŠ: {output_file.name}")

        return corrections_made

    def review_all(self):
        """Review all 15 files"""
        print("=" * 80)
        print("ğŸ” Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ© Ø§Ù„Ø´Ø§Ù…Ù„Ø©")
        print("=" * 80)

        total_corrections = 0

        for i in range(1, 16):
            corrections = self.review_file(i)
            total_corrections += corrections

        print("\n" + "=" * 80)
        print("ğŸ“Š Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©")
        print("=" * 80)
        print(f"Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ÙƒÙ„Ù…Ø§Øª: {self.stats['total']:,}")
        print(f"ØµØ­ÙŠØ­Ø© Ù…Ø³Ø¨Ù‚Ø§Ù‹: {self.stats['correct']:,}")
        print(f"ØªÙ… ØªØµØ­ÙŠØ­Ù‡Ø§: {self.stats['corrected']:,}")
        print(f"Ù…Ø§ Ø²Ø§Ù„Øª ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙØ©: {self.stats['unknown']:,}")
        print(f"\nØ¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØªØµØ­ÙŠØ­Ø§Øª: {total_corrections:,}")


if __name__ == '__main__':
    reviewer = MorphologicalReviewer()

    # Review only first file for now
    print("ğŸ“Œ Ù…Ù„Ø§Ø­Ø¸Ø©: Ø³ÙŠØªÙ… Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø£ÙˆÙ„ ÙÙ‚Ø· ÙƒØ¹ÙŠÙ†Ø©")
    print("    Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù…Ø±Ø¶ÙŠØ©ØŒ Ø³Ù†ÙƒÙ…Ù„ Ø§Ù„Ù€ 15 Ù…Ù„Ù\n")

    reviewer.review_file(1)

    print("\n" + "=" * 80)
    print("â¸  ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹Ø© Ù…Ø¤Ù‚ØªØ§Ù‹")
    print("   ÙŠØ±Ø¬Ù‰ Ù…Ø±Ø§Ø¬Ø¹Ø© qu/final/final_01_reviewed.json")
    print("   Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¬ÙŠØ¯Ø©ØŒ Ø³Ù†ÙƒÙ…Ù„ Ø§Ù„Ù€ 14 Ù…Ù„Ù Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ©")
    print("=" * 80)
